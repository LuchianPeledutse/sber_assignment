{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec00d50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import time\n",
    "import asyncio\n",
    "\n",
    "import pyperclip\n",
    "from tqdm import tqdm\n",
    "\n",
    "from telethon import TelegramClient, events, errors\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0609ad25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ENVIRONMENTAL VARIABLES\n",
    "DATASET_PATH = os.getenv(\"NER_DATASET_PATH\")\n",
    "BOT_USERNAME = os.getenv(\"BOT_USERNAME\")\n",
    "\n",
    "API_ID = os.getenv(\"API_ID\")\n",
    "API_HASH = os.getenv(\"API_HASH\")\n",
    "TELEGRAM_NUMBER = os.getenv('TELEGRAM_NUMBER')\n",
    "TELEGRAM_PASSWORD = os.getenv('TELEGRAM_PASSWORD')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9f75cd",
   "metadata": {},
   "source": [
    "### Задание 1\n",
    "- **1.1.1** Задача с точки зрения NLP состоит в обработке и трансформации текстовых данных в нужный (обычно численный) формат для применения методов ML.\n",
    "\n",
    "- **1.2.1** Задача извлечения сущностей представляет собой распознавание частей текста (скорее всего обработанного), которые представляют собой сущности (что такое сущности определется постановкой задачи), и их классификацию по средством присваивания им метки из заранее определенного набора сущностных меток (например, человек, организация, глагол и тд)\n",
    "\n",
    "- **1.2.2** Классические методы: метод, основанный на использовании регулярных выражений (работает непосредственно с текстом). Методы основанные на классическом ML (численная обработка не связанная напрямую с нейронными сетями). К классическому ML можно отнести такие подходы как вероятностные и CRF модели.\n",
    "\n",
    "- **1.3.1** Задачу NER с помощью LLM можно решать с помощью подхода prompt-engineering'a используя разные тактики (CoT, in-context, few-shot learning и тд.); Если позволяют ресурсы можно слегка (LoRA) дообучить модель на конкретной downstream задаче (в данном случае NER)\n",
    "\n",
    "- **1.4.1** Зависит от постановки задачи. Обычно оценка задачи проводится по классическим метрикам классификации accuracy, precision, recall, f1-score. Если в задаче используются LLM то часто также считется CER схожесть одной сырой строки с другой.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0f60e6",
   "metadata": {},
   "source": [
    "### Задание 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5c115da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(dataset_path: str = DATASET_PATH) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads data into dataframe by folder path\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset_path: str\n",
    "        Path to dataset folder (folder that occurs after unzipping sample data)\n",
    "    \"\"\"\n",
    "    # Creating list to store resulting frame rows\n",
    "    row_list = []\n",
    "    # Getting generators to iterate over paths\n",
    "    raw_docs_path_generator = os.listdir(DATASET_PATH+'raw/ru')\n",
    "    annotated_answer_path_generator = os.listdir(DATASET_PATH+'annotated/ru')\n",
    "\n",
    "    for raw_doc_path in raw_docs_path_generator:\n",
    "        for annotated_answer_path in annotated_answer_path_generator:\n",
    "            # Get ids to match docs and gold answers  \n",
    "            raw_doc_id = re.findall(r\"[0-9]+\", raw_doc_path)[0]\n",
    "            annotated_answer_id = re.findall(r\"[0-9]+\", annotated_answer_path)[0]\n",
    "\n",
    "            if raw_doc_id == annotated_answer_id:\n",
    "                # Read document path to get raw text\n",
    "                with open(DATASET_PATH+'raw/ru/'+raw_doc_path, 'r') as file:\n",
    "                    raw_data_content = file.read()\n",
    "                # Read golden answer lines to get entities and ground truths\n",
    "                with open(DATASET_PATH+'annotated/ru/'+annotated_answer_path, 'r') as file:\n",
    "                    annotated_answer_lines = file.readlines()\n",
    "                \n",
    "                # Normalize answer spaces and capitalization\n",
    "                # Starting from second line to avoid ID line\n",
    "                # Transform list of lines to a list of word lists\n",
    "                splitted_answer_lines = [re.split(r\"\\s+\",line.lower()) for line in annotated_answer_lines[1:]]\n",
    "                empty_removed_answer_lines = [[word for word in line if word != ''] for line in splitted_answer_lines] \n",
    "                # Separate with tabs and spaces\n",
    "                result_list_lines = []\n",
    "                for one_word_list_line in empty_removed_answer_lines:\n",
    "                    N = len(one_word_list_line)\n",
    "                    # Calculate where the tab should be\n",
    "                    tab_indx = (N-2)//2 \n",
    "                    # Prapare for regular space separation\n",
    "                    space_sep_list = [one_word_list_line[:tab_indx],\n",
    "                                      one_word_list_line[tab_indx:N-2]]\n",
    "                    # Prepare for tab separation\n",
    "                    tab_sep = [' '.join(word_list) for word_list in space_sep_list] + one_word_list_line[-2:]\n",
    "                    result_list_lines.append('\\t'.join(tab_sep))\n",
    "                \n",
    "                # Join lines with new lines to return normalized golden answer \n",
    "                golden_answer = '\\n'.join(result_list_lines)\n",
    "                # Find entities from golden answer to add to row\n",
    "                entity = re.findall(r\"\\s[loc|per|org|evt|pro]+\\s\", golden_answer)\n",
    "                stripped_entity = [ent.strip() for ent in entity]\n",
    "\n",
    "                # Creating and appending to row_list for further df creation\n",
    "                row_to_append = {\n",
    "                    \"document_id\": raw_doc_id,\n",
    "                    \"document_text\": raw_data_content,\n",
    "                    \"entity\": stripped_entity,\n",
    "                    \"golden_answer\": golden_answer\n",
    "                }\n",
    "                row_list.append(row_to_append)\n",
    "    return pd.DataFrame(row_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58230b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9 entries, 0 to 8\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   document_id    9 non-null      object\n",
      " 1   document_text  9 non-null      object\n",
      " 2   entity         9 non-null      object\n",
      " 3   golden_answer  9 non-null      object\n",
      "dtypes: object(4)\n",
      "memory usage: 420.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "dataset = get_dataset()\n",
    "print(dataset.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7241cf56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_id</th>\n",
       "      <th>document_text</th>\n",
       "      <th>entity</th>\n",
       "      <th>golden_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1006</td>\n",
       "      <td>ru-1006\\nru\\n2018-07-09\\nhttp://polit.ru/news/...</td>\n",
       "      <td>[evt, pro, per, per, loc, loc, per, per, per, ...</td>\n",
       "      <td>brexit\\tbrexit\\tevt\\tevt-brexit\\nfacebook\\tfac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1003</td>\n",
       "      <td>ru-1003\\nru\\n2018-07-09\\nhttps://echo.msk.ru/n...</td>\n",
       "      <td>[per, loc, loc, per, per, org, per, org, per, ...</td>\n",
       "      <td>борис джонсон\\tборис джонсон\\tper\\tper-boris-j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1017</td>\n",
       "      <td>ru-1017\\nru\\n2018-07-09\\nhttp://www.unn.com.ua...</td>\n",
       "      <td>[evt, pro, per, per, per, per, loc, per, per, ...</td>\n",
       "      <td>brexit\\tbrexit\\tevt\\tevt-brexit\\nthe guardian\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  document_id                                      document_text  \\\n",
       "0        1006  ru-1006\\nru\\n2018-07-09\\nhttp://polit.ru/news/...   \n",
       "1        1003  ru-1003\\nru\\n2018-07-09\\nhttps://echo.msk.ru/n...   \n",
       "2        1017  ru-1017\\nru\\n2018-07-09\\nhttp://www.unn.com.ua...   \n",
       "\n",
       "                                              entity  \\\n",
       "0  [evt, pro, per, per, loc, loc, per, per, per, ...   \n",
       "1  [per, loc, loc, per, per, org, per, org, per, ...   \n",
       "2  [evt, pro, per, per, per, per, loc, per, per, ...   \n",
       "\n",
       "                                       golden_answer  \n",
       "0  brexit\\tbrexit\\tevt\\tevt-brexit\\nfacebook\\tfac...  \n",
       "1  борис джонсон\\tборис джонсон\\tper\\tper-boris-j...  \n",
       "2  brexit\\tbrexit\\tevt\\tevt-brexit\\nthe guardian\\...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e86c99",
   "metadata": {},
   "source": [
    "### Задание 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a04abf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(dataframe_row: pd.Series) -> str:\n",
    "    \"\"\"\n",
    "    Given dataframe row returns a prompt for LLM to solve NER task for that row\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataframe_row: pd.Series\n",
    "        Dataframe row to solve for\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    prompt: str\n",
    "        Prompt for LLM to solve NER for document_text \n",
    "    \"\"\"\n",
    "    document_text = dataframe_row['document_text']\n",
    "    main_prompt = f\"\"\"\n",
    "    Задание: Решить задачу NER на экспертном уровне для заданного документа и заданных меток.\n",
    "    Метки: per(люди); org(организации); loc(локации, места); evt(мироприятия, евенты); pro(продукты)\n",
    "    Документ: {document_text}\n",
    "    ---\n",
    "    Форматирование ответа:\n",
    "    1. Ответ должен содержать только решение для заданной задачи и ничего больше.\n",
    "    2. Решение задачи содержит строки, состоящие из 4-x элементов (имя сущности в документе, начальная форма имени, метка сущности, идентификатор на английском), разделенных '\\t'\n",
    "    3. Если элемент разделяемый, то разделение осуществляется пробелом (дональд трамп, the times, наполеон бонапарт)\n",
    "    4. Строки разделяются '\\n'\n",
    "    5. Ответ должен быть приведен к нижнему регистру\n",
    "    ---\n",
    "    Примеры:\n",
    "    1. В Пакистане проходят акции исламистов против отмены Верховным судом смертного приговора за богохульство христианке Асии Биби. -> \n",
    "    пакистане\\tпакистан\\tloc\\tgpe-pakistan\n",
    "    верховным судом\\tверховный суд\\torg\\torg-supreme-court-of-pakistan\n",
    "    асии биби\\tасия биби\\tper\\tper-asia-bibi\n",
    "    2. В Екатерининском зале Кремля прошла встреча Владимира Путина с участниками Конгресса молодых учёных. ->\n",
    "    екатерининском зале кремля\\tекатерининский зал кремля\\tloc\\tloc-st-catherine-hall\n",
    "    владимира путина\\tвладимир путин\\tper\\tper-vladimir-putin\n",
    "    конгресса молодых учёных\\tконгресс молодых учёных\\tevt\\tevt-congress-of-young-scientists\n",
    "    3. Дженсен Хуанг представил видеокарту GeForce RTX 50 на GTC 2025 Washington D.C. Keynote. -> \n",
    "    дженсен хуанг\\tдженсен хуанг\\tper\\tper-jensen-huang\n",
    "    видеокарту GeForce RTX 50\\tвидеокарта geforce rtx 50\\tpro\\tgpu-geforce-rtx-50\n",
    "    gtc 2025 washington d.c. keynote\\tgtc 2025 washington d.c. keynote\\tevt\\tgtc-2025-washington-dc-keynote\n",
    "    ---\n",
    "    Делать:\n",
    "    1. Проводить анализ и записывать сущности последовательно по мере их появления в предложениях\n",
    "    2. Если сущность как слово находится в сущности как словосочетание в ответ записывать обе\n",
    "    3. Не забывать о том, что в документе может содержаться больше чем одно предложение\n",
    "    4. Первые имена сущностей записывать также, как и в документах на таких же языках\n",
    "    5. Даже если присутствуют сущности разного склонения, в ответ включать все склонения как отдельные строки \n",
    "    6. Первое слово в идентификаторе до - должно быть меткой (per, loc, org, evt, pro) или gpe и ничего больше\"\"\"\n",
    "    return main_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d2a895",
   "metadata": {},
   "source": [
    "### Задание 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b04d8684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-steps verification is enabled and a password is required (caused by SignInRequest)\n",
      "\n",
      "Logged in successfully!\n",
      "Logged in as: Лучиан\n"
     ]
    }
   ],
   "source": [
    "# Client session initialization\n",
    "client = TelegramClient('session', API_ID, API_HASH)\n",
    "\n",
    "async def main():\n",
    "    await client.connect()\n",
    "\n",
    "    # Authorize\n",
    "    await client.send_code_request(TELEGRAM_NUMBER)\n",
    "    code = input(\"Enter the code: \")\n",
    "    password = TELEGRAM_PASSWORD\n",
    "    try:\n",
    "        await client.sign_in(TELEGRAM_NUMBER, code)\n",
    "    except errors.SessionPasswordNeededError as error_message:\n",
    "        print(error_message, end='\\n\\n')\n",
    "        await client.sign_in(password=password)\n",
    "\n",
    "    print(\"Logged in successfully!\")\n",
    "    me = await client.get_me()\n",
    "    print(f\"Logged in as: {me.first_name}\")\n",
    "\n",
    "    await client.disconnect()\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec923d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def ask(message):\n",
    "    await client.start()\n",
    "    async with client.conversation(BOT_USERNAME, timeout=60) as conv:\n",
    "        await conv.send_message(message)\n",
    "        while True:\n",
    "            response = await conv.get_response()\n",
    "            if response.text.split(',')[0] == 'Запрос принят':\n",
    "                time.sleep(1)\n",
    "                continue\n",
    "            else:\n",
    "                return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccded462",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_predictions(dataset_frame: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Given a dataset containing document texts returns model predictions for them\n",
    "    \"\"\"\n",
    "    doc_id_row_list = []\n",
    "    prediction_row_list = []\n",
    "    for row_id in range(len(dataset_frame)-1):\n",
    "        llm_prompt = get_prompt(dataset_frame.iloc[row_id])\n",
    "        llm_response = await ask(llm_prompt)\n",
    "        #append necessary results\n",
    "        prediction_row_list.append(llm_response)\n",
    "        doc_id_row_list.append(dataset_frame.iloc[row_id][\"document_id\"])\n",
    "    return pd.DataFrame({\"document_id\":doc_id_row_list, \"prediction\":prediction_row_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04d6732f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_frame = await get_predictions(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "327e5de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "борис джонсон борис джонсон per per-boris-johnson\n",
      "министр иностранных дел великобритании министр иностранных дел великобритании org org-minister-of-foreign-affairs-of-the-united-kingdom\n",
      "великобритания великобритания loc gpe-united-kingdom\n",
      "дэвид дэвис дэвид дэвис per per-david-davis\n",
      "министр по вопросам выхода великобритании из ес министр по вопросам выхода великобритании из ес org org-minister-for-brexit\n",
      "стив бейкер стив бейкер per per-steve-baker\n",
      "заместитель министра заместитель министра org org-deputy-minister\n",
      "brexit brexit evt evt-brexit\n",
      "тереза мэй тереза мэй per per-theresa-may\n",
      "премьер-министр великобритании премьер-министр великобритании org org-prime-minister-of-the-united-kingdom\n",
      "соединенное королевство соединенное королевство loc gpe-united-kingdom\n",
      "the guardian the guardian org org-guardian\n",
      "унн унн org org-unn\n",
      "британского парламента британский парламент org org-parliament-of-the-united-kingdom\n"
     ]
    }
   ],
   "source": [
    "print(predictions_frame.iloc[3]['prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4995a2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#last document is too long (do manually)\n",
    "llm_prompt = get_prompt(dataset.iloc[-1])\n",
    "pyperclip.copy(llm_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "549b6c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = \"\"\"\n",
    "тереза мэй  тереза мэй  per  per-theresa-may\n",
    "британии  великобритания  loc  gpe-united-kingdom\n",
    "сми  средства массовой информации  org  org-media\n",
    "сентября  сентябрь  time  month-september\n",
    "конференции  конференция  evt  evt-conference\n",
    "партию  партия  org  org-party\n",
    "тори  тори  org  org-conservative-party\n",
    "фаворит  фаворит  per  per-favorite\n",
    "букмекеров  букмекеры  org  org-bookmakers\n",
    "сменщик  сменщик  per  per-successor\n",
    "премьера  премьер-министр  per  per-prime-minister\n",
    "бывший  бывший  adj  former\n",
    "министр  министр  org  org-minister\n",
    "иностранных дел  иностранный отдел  org  org-foreign-affairs\n",
    "британии  великобритания  loc  gpe-united-kingdom\n",
    "борис джонсон  борис джонсон  per  per-boris-johnson\n",
    "доклад  доклад  doc  document-alternative-report\n",
    "взглядов  взгляд  pro  viewpoint-opinion\n",
    "главы  глава  per  per-leader\n",
    "правительства  правительство  org  org-government\n",
    "условия  условие  pro  condition-term\n",
    "brexit  brexit  evt  evt-brexit\n",
    "точки  точка  pro  point-of-view\n",
    "лондон  лондон  loc  gpe-london\n",
    "обернул  обернуть  act  wrap-action\n",
    "британскую  британский  adj  british\n",
    "конституцию  конституция  pro  constitution-charter\n",
    "поясом  пояс  obj  explosive-belt-object\n",
    "смертника  смертник  per  suicide-bomber-person\n",
    "вручил  вручить  act  handover-action\n",
    "детонатор  детонатор  obj  detonator-object\n",
    "мишель барнье  мишель барнье  per  per-michel-barnier\n",
    "переговорщик  переговорщик  per  negotiator-person\n",
    "брюсселя  брюссель  loc  gpe-brussels\n",
    "конференции  конференция  evt  conference-event\n",
    "альбиона  альбион  loc  gpe-albion\n",
    "лондон  лондон  loc  gpe-london\n",
    "брюссель  брюссель  loc  gpe-brussels\n",
    "39 миллиардов фунтов стерлингов  фунт стерлингов  pro  currency-gbp\n",
    "законы ес  законы ес  pro  eu-laws\n",
    "северная ирландия  северная ирландия  loc  gpe-northern-ireland\n",
    "таможенный союз  таможенный союз  org  customs-union\n",
    "европы  европа  loc  gpe-europe\n",
    "британия  великобритания  loc  gpe-united-kingdom\n",
    "борис джонсон  борис джонсон  per  per-boris-johnson\n",
    "союз  союз  org  alliance\n",
    "брюссель  брюссель  loc  gpe-brussels\n",
    "англичан  англичанин  per  per-englishmen\n",
    "территории  территория  loc  territory\n",
    "соединенное королевство  соединенное королевство  loc  gpe-united-kingdom\n",
    "брексит  брексит  evt  evt-brexit\n",
    "мэй  тереза мэй  per  per-theresa-may\n",
    "четверг  четверг  time  weekday-thursday\n",
    "саммит  саммит  evt  summit-event\n",
    "брюссель  брюссель  loc  gpe-brussels\n",
    "евросоюз  европейский союз  org  org-european-union\n",
    "альбион  альбион  loc  gpe-albion\n",
    "борис джонсон  борис джонсон  per  per-boris-johnson\n",
    "мэй  тереза мэй  per  per-theresa-may\n",
    "британский  великобритания  loc  gpe-united-kingdom\n",
    "мида  министерство иностранных дел  org  org-ministry-of-foreign-affairs\n",
    "среда  среда  time  week-day-wednesday\n",
    "экстренного саммита  экстренный саммит  evt  evt-emergency-summit\n",
    "евросоюза  европейский союз  org  org-european-union\n",
    "австрийский  австрия  loc  gpe-austria\n",
    "себастьян курц  себастьян курц  per  per-sebastian-kurz\n",
    "канцлер  канцлер  org  org-chancellor\n",
    "брюссель  брюссель  loc  gpe-brussels\n",
    "брекзит  брекзит  evt  evt-brexit\n",
    "делов  сделка  pro  deal-agreement\n",
    "конференции  конференция  evt  evt-conference\n",
    "консервативной партии  консервативная партия  org  org-conservative-party\n",
    "лондону  лондон  loc  gpe-london\n",
    "хаоса  хаос  evt  evt-chaos\n",
    "кресло  кресло  furn  chair-seat\n",
    "британского премьера  британский премьер-министр  per  per-british-prime-minister\n",
    "триумфальное возвращение  триумфальное возвращение  evt  evt-triumphant-return\n",
    "британские букмекерские конторы  британские букмекерские конторы  org  org-british-bookmakers\n",
    "бывший министр иностранных дел  бывший министр иностранных дел  per  per-former-foreign-minister\n",
    "кандидат  кандидат  per  per-candidate\n",
    "фаворит  фаворит  per  per-favorite\n",
    "премьера  премьер-министр  per  per-prime-minister\n",
    "мэй  тереза мэй  per  per-theresa-may\n",
    "лондон  лондон  loc  gpe-london\n",
    "евросоюз  европейский союз  org  org-european-union\n",
    "эксперты международного валютного фонда  международные эксперты  org  org-international-experts\n",
    "международный валютный фонд  международный валютный фонд  org  org-international-monetary-fund\n",
    "ла-манш  пролив ла-манш  loc  gpe-la-manche\n",
    "бизнес  бизнес  org  business-entity\n",
    "лекарственные препараты  лекарственный препарат  pro  pharmaceutical-product\n",
    "еврокомиссия  еврокомиссия  org  org-european-commission\n",
    "финансовые рынки  финансовый рынок  org  financial-market\n",
    "лидеры руководства  руководство  org  leadership\n",
    "евросоюза  европейский союз  org  org-european-union\n",
    "соглашение  соглашение  pro  agreement-deal\n",
    "брюссель  брюссель  loc  gpe-brussels\n",
    "европейский парламент  европейский парламент  org  org-european-parliament\n",
    "британский парламент  британский парламент  org  org-british-parliament\n",
    "лейбористы  лейбористы  org  org-labour-party\n",
    "компромисс  компромисс  pro  compromise-outcome\n",
    "альбион  альбион  loc  gpe-albion\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "787156de",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_frame.loc[8] = [dataset.iloc[-1][\"document_id\"], prediction.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "780a86e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_frame.to_csv('predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
